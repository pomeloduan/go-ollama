中文 | [English](README.md)

目前AI Agent的实现多以Python为主，Go语言的相关实践较为缺乏。本项目旨在使用Go语言完整实现一套可本地运行的AI Agent系统，希望能够：
1. 作为个人学习总结
2. 为Go社区提供AI开发的参考示例
3. 与其他关注AI agent开发和Go语言的小伙伴交流

# Ollama 本地服务 Demo

这是一个 Go 语言演示项目，展示了如何用最少代码调用本地 Ollama AI 模型。

本项目构建了包含如下功能的智能体系统：

- **提示词管理**：优化与模型的对话指令
- **上下文维护**：保持多轮对话连贯性
- **RAG 集成**：集成检索增强生成技术，提升专业问题解答的准确性
- **多智能体协作**：采用集中式架构，由协调者分配任务，专家智能体处理特定领域问题
- **评审者模式**：遵循 生成→评审→改进 流程，确保输出质量持续优化
- **智能体配置化**：使用 YAML 文件动态定义和生成专家和评审者智能体

```
. . . . . . . . . . . . . . . . . . .
.
. Agent Manager
.                 │
.          ┌──────▼──────┐
.          │ Coordinator │
.          │ ---         │
.          │ Analysis    │
.          │ Matching    │
.          └──────┬──────┘
.                 │
.      ┌──────────┴─────────┐
       │                    │
┌──────▼──────┐       ┌─────▼─────┐
│ Specialist  │       │ Reviewer  │
│ ---         │◄──┐   │ ---       │
│ - hp        │   └──►│ Scoring   │       ┌─────────────┐
│ - math      │-------│ Feedback  │------►│ Rag Manager │
│ - poet      │       └─────┬─────┘       │ ---         │
│ ...         │             │             │ Chucking    │
└──────┬──────┘             │             │     ↓       │
       │                    │             │ Embedding + │
       └──────────┬─────────┘             │     ↓     +-│--→ Gse Segmentation
                  │                       │ Retrieval + │    Chromem Vector DB
         ┌────────▼────────┐              │     ↓       │    ┌──────────┐
         │ Ollama Manager  │              │ Reranking +-│---►│ Reranker │
         │ ---             │              └─────────────┘    └─────┬────┘
         │ Ollama Service  │◄──────────────────────────────────────┘
         │ Local LLM       │
         └─────────────────┘

```

### RAG效果
(需要访问外部知识《哈利波特与魔法石》内容)
```
知识库预处理，需要一些时间
进度：100.0% 第109项，共109项
等待提问 -->
哈利和罗恩认为谁想去偷魔法石？
哈利和罗恩认为斯内普（西弗勒斯·斯内普）是想要偷魔法石的人。在对话中，罗恩明确表示：“如果再不抓紧时间，他就已经把魔法石拿到手了！”
这里的“他”指的是斯内普。而哈利在得知斯内普可能参与偷魔法石后，立即建议三人一起行动，以阻止他。
等待提问 -->
下棋的过程中，哈利代替了什么棋子，罗恩代替了什么棋子？
根据文本内容，在下棋的过程中：
哈利代替了主教的位置。
罗恩代替了骑士的角色。
赫敏则代替了城堡。三人通过扮演棋子并遵循象棋规则，最终战胜了白棋，成功通过了房间。
```

## 功能特性

- 连接到本地 Ollama 服务
- 简单的命令行界面
- 可配置的模型参数
- 错误处理和日志记录

## 前提条件

在运行此项目之前，请确保：

1. **安装 Go**: 版本 1.23 或更高
   ```bash
   # 检查 Go 版本
   go version
   ```

2. **安装并运行 Ollama**: 
   - 访问 [Ollama 官网](https://ollama.ai/) 下载并安装
   - 启动 Ollama 服务
   - 下载至少一个语言模型，例如：
     ```bash
     ollama pull llama2
     ollama pull mistral
     ```
   - 下载至少一个向量模型

## 注意事项

1. **确保 Ollama 服务正在运行**：
   ```bash
   # 检查 Ollama 服务状态
   curl http://localhost:11434/api/tags
   ```

2. **模型可用性**：确保所需的模型已下载并可用

3. **性能考虑**：根据模型大小和硬件配置，响应时间可能有所不同

## 常见问题

1. **连接失败**：
   - 检查 Ollama 服务是否运行：`ollama serve`
   - 确认端口 11434 是否可用

2. **模型未找到**：
   - 列出已安装的模型：`ollama list`
   - 下载所需模型：`ollama pull <model-name>`

3. **内存不足**：
   - 尝试使用较小的模型
   - 关闭其他占用内存的应用程序

## 日志查看

```
info.log
```


## 相关链接

- [Ollama 官网](https://ollama.ai/)
- [Ollama GitHub](https://github.com/ollama/ollama)
- [Go 官方文档](https://golang.org/doc/)

**提示**: 这是一个演示项目，适用于学习和测试目的。
